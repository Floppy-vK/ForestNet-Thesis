{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purposes\n",
    "This notebook is used to convert the existing dataset images to numpy arrays, pairing them up with other images to increase input complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new CSV files which only include examples that contain cloud filtered images along with composite images\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#read through all files in training, val, and test sets\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test.csv')\n",
    "\n",
    "train_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "val_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "test_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "\n",
    "\n",
    "#check to see if cloud filtered image is available\n",
    "for example_set_df, set_dict, set_path in zip([train, val, test], [train_dict, val_dict, test_dict], ['train_new.csv', 'val_new.csv', 'test_new.csv']):   \n",
    "    for i in range(example_set_df.shape[0]):\n",
    "            img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "            list_of_images = glob.glob(img_path + '/*.png')\n",
    "            if len(list_of_images) > 1:\n",
    "                  for col in ['label', 'merged_label', 'latitude', 'longitude', 'year', 'example_path']:\n",
    "                    set_dict[col].append(example_set_df[col][i])\n",
    "    set_df = pd.DataFrame(set_dict)\n",
    "    set_df.to_csv('../input/forestnet/ForestNetDataset/' + set_path, index=False)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ! Run the block directly below before running any other blocks below it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read new CSV files and create dictionaries for all sets\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#read through all files in training, val, and test sets\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "train_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "val_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "test_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_p&sa.csv is 78.03379416282642% the size of the corresponding \"new\" set.\n",
      "val_p&sa.csv is 77.22513089005236% the size of the corresponding \"new\" set.\n",
      "test_p&sa.csv is 74.18738049713193% the size of the corresponding \"new\" set.\n",
      "{('Smallholder agriculture', 'Small-scale mixed plantation'), ('Smallholder agriculture', 'Small-scale agriculture'), ('Plantation', 'Timber plantation'), ('Plantation', 'Oil palm plantation'), ('Plantation', 'Other large-scale plantations'), ('Smallholder agriculture', 'Small-scale oil palm plantation')}\n"
     ]
    }
   ],
   "source": [
    "# Run this block to: create new CSV files which only include examples that have the Plantation merged_label ()\n",
    "plantation_labels = set()\n",
    "\n",
    "#check to see if cloud filtered image is available\n",
    "for example_set_df, set_dict, set_path in zip([train, val, test], [train_dict, val_dict, test_dict], ['train_plantation.csv', 'val_plantation.csv', 'test_plantation.csv']):   \n",
    "    for i in range(example_set_df.shape[0]):\n",
    "      img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "      #filter out all plantations\n",
    "      if example_set_df['merged_label'][i] == 'Plantation':\n",
    "            for col in ['label', 'merged_label', 'latitude', 'longitude', 'year', 'example_path']:\n",
    "              set_dict[col].append(example_set_df[col][i])\n",
    "              plantation_labels.add(example_set_df['label'][i])\n",
    "    set_df = pd.DataFrame(set_dict)\n",
    "    set_df.to_csv('../input/forestnet/ForestNetDataset/' + set_path, index=False)\n",
    "\n",
    "    print(f'{set_path} is {set_df.shape[0]/example_set_df.shape[0] * 100}% the size of the corresponding \"new\" set.')\n",
    "\n",
    "print(plantation_labels)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to: create new CSV files which only include examples that have the Plantation and Smallholder Agriculture merged_label(s)\n",
    "\n",
    "\n",
    "unique_labels = set()\n",
    "\n",
    "#check to see if cloud filtered image is available\n",
    "for example_set_df, set_dict, set_path in zip([train, val, test], [train_dict, val_dict, test_dict], ['train_p&sa.csv', 'val_p&sa.csv', 'test_p&sa.csv']):   \n",
    "    for i in range(example_set_df.shape[0]):\n",
    "      img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "      #filter out all plantations\n",
    "      if example_set_df['merged_label'][i] in ['Plantation', 'Smallholder agriculture'] :\n",
    "            for col in ['label', 'merged_label', 'latitude', 'longitude', 'year', 'example_path']:\n",
    "              set_dict[col].append(example_set_df[col][i])\n",
    "              unique_labels.add((example_set_df['merged_label'][i], example_set_df['label'][i]))\n",
    "    set_df = pd.DataFrame(set_dict)\n",
    "    set_df.to_csv('../input/forestnet/ForestNetDataset/' + set_path, index=False)\n",
    "\n",
    "    print(f'{set_path} is {set_df.shape[0]/example_set_df.shape[0] * 100}% the size of the corresponding \"new\" set.')\n",
    "\n",
    "print(unique_labels)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to: generate new images by alpha composite blending the most recent cloud filtered image with the composite image, with alpha value a.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#path to set csv files\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "a = 0.15\n",
    "\n",
    "for example_set_df in [train, val, test]:\n",
    "    for i in range(example_set_df.shape[0]):\n",
    "        img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "        #get list of files in directory\n",
    "        list_of_files = glob.glob(img_path + '/*.png')\n",
    "        #loads example's composite image\n",
    "        composite_img = Image.open(list_of_files[-1])\n",
    "        #loads most recent cloud filtered image\n",
    "        cloudf_img = Image.open(list_of_files[-2])\n",
    "        blended_img = Image.blend(composite_img, cloudf_img, a)\n",
    "        blended_img.save(img_path + f'/blended_images_alpha_{a}.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to: generate new images by alpha composite blending the most composite image with its infrared twin, using alpha value a.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#path to set csv files\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "a = 0.5\n",
    "\n",
    "for example_set_df in [train, val, test]:\n",
    "    for i in range(example_set_df.shape[0]):\n",
    "        img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/'\n",
    "        composite_img = Image.open(img_path + 'visible/composite.png')\n",
    "        #load infrared image\n",
    "        comp_ir_npy = np.load(img_path + 'infrared/composite.npy') \n",
    "        comp_ir_img = Image.fromarray(comp_ir_npy, mode = \"RGB\")    \n",
    "        blended_img = Image.blend(composite_img, comp_ir_img, a)\n",
    "        blended_img.save(img_path + f'visible/blended_infrared_{a}.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to: generate new images by concatenating composite and cloud filtered images as NumPy arrays using np.concatenate\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#path to set csv files\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "\n",
    "for example_set_df in [train, val, test]:\n",
    "    for i in range(example_set_df.shape[0]):\n",
    "        img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "        #get list of files in directory\n",
    "        list_of_files = glob.glob(img_path + '/*.png')\n",
    "        #loads example's composite image\n",
    "        composite_img = Image.open(list_of_files[-1])\n",
    "        #loads most recent cloud filtered image\n",
    "        cloudf_img = Image.open(list_of_files[-2])\n",
    "        #convert to np-array\n",
    "        np_composite_img = np.asarray(composite_img)\n",
    "        np_cloudf_img = np.asarray(cloudf_img)\n",
    "        # COULD ALSO USE DIFFERENT AXIS TO GET NON-SQUARE IMAGE, I DON'T THINK THAT'S A GOOD IDEA\n",
    "        np_new = np.concatenate((np_composite_img, np_cloudf_img), 2)\n",
    "        np.save(img_path + \"/concatenated_images.npy\", np_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
