{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purposes\n",
    "This notebook is used to convert the existing dataset images to numpy arrays, pairing them up with other images to increase input complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new CSV files which only include examples that contain cloud filtered images along with composite images\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#read through all files in training, val, and test sets\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test.csv')\n",
    "\n",
    "train_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "val_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "test_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "\n",
    "\n",
    "#check to see if cloud filtered image is available\n",
    "for example_set_df, set_dict, set_path in zip([train, val, test], [train_dict, val_dict, test_dict], ['train_new.csv', 'val_new.csv', 'test_new.csv']):   \n",
    "    for i in range(example_set.shape[0]):\n",
    "            img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "            list_of_images = glob.glob(img_path + '/*.png')\n",
    "            if len(list_of_images) > 1:\n",
    "                  for col in ['label', 'merged_label', 'latitude', 'longitude', 'year', 'example_path']:\n",
    "                    set_dict[col].append(example_set_df[col][i])\n",
    "    set_df = pd.DataFrame(set_dict)\n",
    "    set_df.to_csv('../input/forestnet/ForestNetDataset/' + set_path, index=False)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_plantation.csv is 43.16436251920123% the size of the corresponding \"new\" set.\n",
      "val_plantation.csv is 45.811518324607334% the size of the corresponding \"new\" set.\n",
      "test_plantation.csv is 39.961759082217974% the size of the corresponding \"new\" set.\n",
      "{'Other large-scale plantations', 'Timber plantation', 'Oil palm plantation'}\n"
     ]
    }
   ],
   "source": [
    "# Create new CSV files which only include examples that have the Plantation merged_label\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#read through all files in training, val, and test sets\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "train_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "val_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "test_dict = {'label':[], 'merged_label': [], 'latitude': [], 'longitude': [], 'year': [], 'example_path': []}\n",
    "\n",
    "plantation_labels = set()\n",
    "\n",
    "#check to see if cloud filtered image is available\n",
    "for example_set_df, set_dict, set_path in zip([train, val, test], [train_dict, val_dict, test_dict], ['train_plantation.csv', 'val_plantation.csv', 'test_plantation.csv']):   \n",
    "    for i in range(example_set_df.shape[0]):\n",
    "      img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "      #filter out all plantations\n",
    "      if example_set_df['merged_label'][i] == 'Plantation':\n",
    "            for col in ['label', 'merged_label', 'latitude', 'longitude', 'year', 'example_path']:\n",
    "              set_dict[col].append(example_set_df[col][i])\n",
    "              plantation_labels.add(example_set_df['label'][i])\n",
    "    set_df = pd.DataFrame(set_dict)\n",
    "    set_df.to_csv('../input/forestnet/ForestNetDataset/' + set_path, index=False)\n",
    "\n",
    "    print(f'{set_path} is {set_df.shape[0]/example_set_df.shape[0] * 100}% the size of the corresponding \"new\" set.')\n",
    "\n",
    "print(plantation_labels)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO ONLY INCLUDE EXAMPLES WITH COMPOSITE AND CLOUD FILTERED IMAGES USING np.concatenate\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#path to set csv files\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "\n",
    "for example_set_df in [train, val, test]:\n",
    "    for i in range(example_set_df.shape[0]):\n",
    "        img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "        #get list of files in directory\n",
    "        list_of_files = glob.glob(img_path + '/*.png')\n",
    "        #loads example's composite image\n",
    "        composite_img = Image.open(list_of_files[-1])\n",
    "        #loads most recent cloud filtered image\n",
    "        cloudf_img = Image.open(list_of_files[-2])\n",
    "        #convert to np-array\n",
    "        np_composite_img = np.asarray(composite_img)\n",
    "        np_cloudf_img = np.asarray(cloudf_img)\n",
    "        # COULD ALSO USE DIFFERENT AXIS TO GET NON-SQUARE IMAGE, I DON'T THINK THAT'S A GOOD IDEA\n",
    "        np_new = np.concatenate((np_composite_img, np_cloudf_img), 2)\n",
    "        np.save(img_path + \"/concatenated_images.npy\", np_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION TO ONLY INCLUDE EXAMPLES WITH COMPOSITE AND CLOUD FILTERED IMAGES USING PIL.Image.blend\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#path to set csv files\n",
    "train = pd.read_csv('../input/forestnet/ForestNetDataset/train_new.csv')\n",
    "val = pd.read_csv('../input/forestnet/ForestNetDataset/val_new.csv')\n",
    "test = pd.read_csv('../input/forestnet/ForestNetDataset/test_new.csv')\n",
    "\n",
    "\n",
    "for example_df in [train, val, test]:\n",
    "    for i in range(example_set_df.shape[0]):\n",
    "        img_path = f'../input/forestnet/ForestNetDataset/{example_set_df[\"example_path\"][i]}/images/visible'\n",
    "        #get list of files in directory\n",
    "        list_of_files = glob.glob(img_path + '/*.png')\n",
    "        #loads example's composite image\n",
    "        composite_img = Image.open(list_of_files[-1])\n",
    "        #loads most recent cloud filtered image\n",
    "        cloudf_img = Image.open(list_of_files[-2])\n",
    "        blended_img = Image.blend(composite_img, cloudf_img, .5)\n",
    "        blended_img.save(img_path + '/blended_images.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nimport numpy as np\\nfrom PIL import Image\\nnpy_path = '../input/forestnet/ForestNetDataset/examples/0.01805967191228_101.57018668487896/images/visible/concatenated_images.npy'\\nconc_npy = np.load(npy_path)\\nconc_img = Image.fromarray(conc_npy)\\nconc_img.save('../input/forestnet/ForestNetDataset/0.01805967191228_101.57018668487896/images/visible/concatenated_images')\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doesn't work due to npy arrays having 6 channels (R,G,B,R,G,B)\n",
    "\"\"\" \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "npy_path = '../input/forestnet/ForestNetDataset/examples/0.01805967191228_101.57018668487896/images/visible/concatenated_images.npy'\n",
    "conc_npy = np.load(npy_path)\n",
    "conc_img = Image.fromarray(conc_npy)\n",
    "conc_img.save('../input/forestnet/ForestNetDataset/0.01805967191228_101.57018668487896/images/visible/concatenated_images')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
